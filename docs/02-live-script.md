# 세션 흐름

## 0. 인트로 (주형 발표)

- [IntroSlide]
- [SpeakerSlide]
~~ 자기 소개

- [PaceSlide]
생성형 AI, 이제는 우리의 업무와 일상에서 빼놓을 수 없습니다.
워낙 많은 관심을 받고 있는 분야라 그런지 발전하고 있는 속도도 빠르고
한번 소식을 가까이 하고 있지 않으면 쌓이는 새로운 소식들을 따라잡는게 어려워지더라구요.

이런 너무나도 빠른 세상에 뒤쳐지고 싶지 않아서 
저는 이런 AI 트렌드를 자주 접하고 있는데요.
이런 AI 소식들을 동료분들한테 쉽게 요약하고 공유하는 걸 좋아합니다.

그렇게 실제로 동료분들의 업무에 도움이 될 때 꽤 뿌듯하더라구요.

오늘 준비한 내용이 여러분들께도 도움이 되기를 바라면서
2025년 생성형 AI 트렌드 총 정리 시작해보겠습니다.

## 1. 키워드
- [KeywordsSlide] 
`Reasoning Model, 컨텍스트 엔지니어링, 나노바나나, veo, 바이브 코딩, 에이전트`

자 먼저 올해 생성형 AI분야에서 핫했던 키워드들부터 이야기해볼게요.

- [ReasoningModelSlide]
첫번째 키워드는 Reasoning Model입니다.
사실 24년 하반기부터 조금씩 모습을 드러냈는데, 25년도가 되면서 비즈니스 현장에 본격적으로 확산되기 시작했어요. 이 모델들의 가장 큰 특징을 꼽으라면, **'답을 내기 전에 더 오래 생각한다'**는 점이에요. 
이전 llm 모델들이 질문을 받으면 비교적 빠르게 계산을 마친 뒤 결과를 던져줬다면, reasoning 모델은 계획을 세우고 → 추론하고 → 중간에 스스로 검증하는 단계를 더 강하게 거칩니다.
한마디로 “정답만 내는 AI”에서 **“생각하고 검산하는 AI”**로 진화한 거죠.

이게 왜 중요하냐면요, 생성형 AI가 스스로 문제를 해결하는 경로를 설계하고 그 과정에서 생기는 논리적 오류를 스스로 검토할 수 있게 됐어요. 

예전에는 사용자가 직접 Chain of Thought 같은 프롬프팅 기법으로 유도하던걸, 이제는 모델이 기본값으로 그런 식의 사고 루틴을 더 잘 수행하도록 만들어진거죠. 덕분에 복잡한 기획안 작성이나 고도의 코딩 작업처럼 '논리적 완결성'이 필요한 업무에서 이전과는 비교할 수 없는 성능을 보여주게 됐습니다.

이렇게 AI가 스스로 논리를 짜기 시작하니까, 우리에게는 또 다른 숙제가 생겼어요. 

- [ContextEngineeringSlide]
AI가 제대로 판단할 수 있게 필요한 재료들을 잘 넣어줘야겠죠? 그게 바로 두 번째 키워드, "컨텍스트 엔지니어링"입니다.

방금 이야기한 reasoning 모델이 “생각하고 검산하는 AI”라면요, 이제부터는 그 AI가 생각할 ‘재료’를 우리가 어떻게 주느냐가 성능을 좌우하기 시작했어요.
쉽게 말해서, 프롬프트 엔지니어링이 '질문을 어떻게 예쁘게 할까'를 고민하는 기술이었다면, 컨텍스트 엔지니어링은 생성형 AI에게 **'어떤 정보를, 어떤 순서로 줄까'**를 설계하는 기술입니다. 모델이 똑똑해진 만큼, 질문 한 줄보다는 참고할 문서, 히스토리, 제약 조건 같은 **'맥락,Context'**를 얼마나 잘 구조화해서 던져주느냐가 결과물의 퀄리티를 결정하게 된 거죠.

- [MediaGenerationSlide]
또 올해는 이미지나 비디오 생성에서도 뛰어난 발전을 보여줬던 해입니다. 타이포그래피가 들어간 이미지 생성은 어려웠었는데 이제는 텍스트도 이미지로 생성이 가능해졌고요. 비디오 생성 같은 경우에도 오디오 없이 영상만 생성할 수 있었는데 네이티브 오디오가 들어간 고품질의 영상을 생성할 수 있게 됐어요.

- [AgentSlide]
그리고 이 모든 키워드들이 모이는 종착역, **Agent(에이전트)**입니다.
아마 올해 가장 많이 들으셨을 단어일거에요.
24년도엔 생성형 AI가 똑똑한 비서, "어시스턴트"라고 불렸다면 
올해는 생성형AI가 에이전트라고 많이 불렸습니다.

어떻게 보면 생성형 AI의 성능이 올라오고, 해결할 수 있는 일이 많아져서 그런지 
지위가 비서에서 동료로 승진을 했죠.

그렇게 25년도 생성형 AI는 우리 곁의 '동료'가 되었습니다. 

- [VibeCodingSlide] 
이런 AI 에이전트는 코드를 짜고 혼자 빌드해서 테스트도 해보고 개발자가 하는 일들을 완전히 대체할 수 있어요. 내가 개발을 모르더라도 코딩을 할 수 있으니, 심지어는 "바이브코딩"이라는 단어도 유행하게 됐고요. 이 바이브 코딩은 결국 사전에 등재까지 됐습니다.

현재는 ai 에이전트가 브라우저를 직접 조작하는것 까지도 가능해요.

이제 '혼자서 일하는 AI'의 시대가 열렸다고 할 수 있겠네요.

- [ThreeDirectionsSlide]
이렇게 키워드로만 봐도 25년이 얼마나 정신없었는지 느껴지시죠? 그런데 재밌는 건, 이 '에이전트'라는 비슷한 목표를 보고 달려가는데 Anthropic, OpenAI, Google 세 회사의 스타일이 완전히 달랐어요.

한 곳은 **'개발자의 손'**을 대신하려 했고, 한 곳은 **'우리의 일상'**을 점유하려 하고, 한 곳은 **'세상의 모든 인프라'**를 AI로 장악하려고 했습니다.

## 2. 3사 타임라인별 쭉 흐름 리뷰
- [CompanyStrategiesSlide]
  - Anthropic: "일의 깊이"
  - OpenAI: "일상의 넓이"
  - Google: "판의 크기"

3사의 전략을 요약해보자면 요런 느낌이에요.
Antrhopic은 "일의 깊이"에 집중했고요. OpenAI는 "일상의 넓이"를 택했습니다. Google은 구글이 가진 방대한 인프라를 활용해서 "판의 크기"를 키우려고 했고요.

자 그럼 25년 동안 Anthropic, OpenAI, Google 이 세 거인이 어떤 발자취를 남겼는지, 월별 타임라인을 통해 자세히 살펴보겠습니다. 모델이 출시된 내용은 가볍게 넘어갈게요.

### [Antrhopic 행성]

- [2월]
먼저 Antrhopic입니다.
Anthropic에선 2월에 Claude 3.7 Sonnet이라는 모델 발표와 함께
Claude Code라는 터미널 기반의 코딩 에이전트를 research preview 형태로 출시했어요.

이 당시에 Cursor, Windsurf, Lovable 같은 툴들이 에이전틱 코딩을 하기위해 많이 유행하던 상태였는데요.

Cursor에서 Claude 모델들을 호출해서 잘 쓰고 있는데 왜 굳이? CLI를? 
처음엔 사람들의 반응도 의아했어요. 그런데 Anthropic이 이렇게 설계한 이유는 사내 개발자들이 사용하는 코드 에디터가 너무 다양하다보니 모두가 쓸 수 있는 방법을 찾다가 CLI 형태가 됐다고 합니다. 어떤 컴퓨터든 기본적으로 있는게 CLI, 터미널이니까요.

Claude Code를 잘 활용하면 지금 보이는 이런 웹사이트를 코딩을 몰라도 자연어로 만들 수가 있습니다.
이 클로드 코드 출시는 꽤 중요했던 내용이라 뒤에서 더 자세히 알아보겠습니다.

- [3월]
3월엔 Anthropic이 발표했던 MCP를 OpenAI에서 공식적으로 채택했습니다.
그리고 경쟁사 대비 다소 늦은편이었지만 웹 검색기능이 클로드에 출시 됐습니다. 이젠 어떤 걸 써도 다 있는 기능이죠. 프롬프트에 "웹 검색해줘"라고 입력만 하면 알아서 검색을 대신해줍니다.

- [5월]
5월에 Claude Code가 정식으로 출시 됐습니다.
이 때 개발자들이 제일 많이 쓰는 VSCode, IntelliJ에 플러그인 형태로 사용할 수도 있게 공식으로 지원하기 시작했어요.

- [8월]
8월엔 Claude for Chrome Research Preview를 발표했는데요.
크롬에서 클로드를 확장 프로그램 형태로 사용하는 툴입니다.

클로드 코드와 클로드 for chrome만 봐도 Anthropic은 플랫폼에 종속되지 않고 누구나 쉽게 접할 수 있게 제품들을 출시하려는게 보이더라구요.

- [9월]
그리고 9월엔 Excel, PPT, PDF를 생성하는 파일 생성 기능이 클로드에 출시 됐습니다.
자연어 만으로 진짜 내가 업무에 필요한 파일들을 짠하고 만드는게 가능해진 거죠.

- [10월]
여기서 놀라운건 10월에 발표된 Claude Skills인데요. 
9월에 출시된 파일생성 기능이 Skills로 만들어졌다고 해요.

Skills는 "저런 파일 생성 기능"을 누구나 쉽게 받아들일 수 있는 우리 컴퓨터에서의 폴더 디렉토리 형태로 구조만 짜면 Claude가 도메인에 특화된 전문적인 작업들을 가능케 해주는 기능이었습니다. 이것도 꽤 중요한 내용이에요.

- [11월]
11월엔 Microsoft의 Excel 프로그램에 빌트인해서 쓸 수 있는 Claude in Excel도 베타로 발표했습니다.

- [12월]
그리고 요번달이죠. 12월엔 내용이 꽤 많습니다.

먼저 Claude Code가 정식 출시된지 6개월만에 1조원의 매출을 달성했다고 합니다. 진짜 어마어마한 수치죠. 이것만 봐도 Anthropic에게 Claude Code가 얼마나 중요한 제품이었는지, 사람들이 얼마나 열광했는지 알 수 있네요.

슬랙에서 클로드를 통합해서 쓸 수 있는 기능이 출시되고, 베타로 있던 Claude for Chrome, 크롬 확장자가 정식 출시 됐습니다.

이제 크롬에서 저 확장자만 설치하면 혼자 일을 해요. 아직은 쪼금 느린 감이 있지만 그래도 내가 워크플로우만 잘 설명하고 녹화하면 이전엔 수동으로 해야했던 일을 자동으로 처리합니다.

Claude for Chrome도 앞으로 꽤 중요한 내용이 될거에요.
단순히 브라우저에서 채팅 인터페이스가 필요한 순간에만 사용하는 게 아니라,
Claude Code와 함께 활용하면서 브라우저를 제어하는게 가능하거든요. 

마지막으로 12월엔 앤스로픽이 자사의 MCP 기술을 리눅스 재단(AAIF)에 전격 기증했습니다. 이건 마치 인터넷의 HTTP처럼, AI 에이전트가 각종 소프트웨어와 소통하는 방식을 **'전 세계 표준'**으로 만들겠다는 선언이에요. 특정 기업의 소유물이 아니라 모두가 쓰는 공용어가 되어야 생태계가 폭발적으로 커질 수 있으니까요. 결국 기술 독점보다는 **'표준 선점'**을 통해 에이전트 시대의 가장 기초적인 뼈대를 앤스로픽의 방식대로 구축하겠다는 큰 그림인 셈입니다.

- [AnthropicSlide]
자, 이렇게 앤스로픽의 25년도를 돌아보면 한 가지 확실한 철학이 보입니다. 이들은 클로드라는 AI를 채팅창 안에 가두지 않았어요. 개발자의 검은 터미널 화면(CLI)부터, 슬랙 사내메신저, 직장인의 크롬 브라우저, 재무팀의 엑셀까지... 우리가 **'일하는 모든 현장'**으로 직접 찾아왔습니다. 결국 앤스로픽은 특정 플랫폼을 만드는 것을 넘어, **'어떤 환경에서든 작동하는 업무의 표준 인터페이스'**가 되는걸 전략적으로 접근하고 있어요. 초보자에게는 쉬운 접근성을, 전문가에게는 날개를 달아주는 도구. 그게 바로 앤스로픽이 보여준 **'일의 깊이'**였습니다.


### [OpenAI 행성]
자, 앤스로픽이 '일 잘하는 동료'였다면, 이번엔 OpenAI입니다. OpenAI의 2025년은 한마디로 **"우리의 일상을 점령하러 왔다"**고 표현할 수 있겠네요.

앤스로픽이 개발자 도구나 업무용 툴에 집중할 때, OpenAI는 소비자들이 피부로 느낄 수 있는 서비스와 디바이스, 그리고 브라우저 영역으로 전략적인 접근을 했습니다.

타임라인으로 한번 볼게요.

가장 먼저 1월, **'Operator'**를 research preview로 출시하며 새해 포문을 열었습니다. 기존에 우리가 컴퓨터를 쓸 때 마우스로 클릭하고, 타이핑하던 걸 AI가 대신해주는 '브라우저 제어 에이전트'인데요. 앤스로픽이 24년도에 'Computer Use'라는 기능을 출시 했었어요. 거기에 대응해서 만든 기능이라고 생각하시면 되고 "비행기 표 예매해줘"라고 하면 내가 보는 앞에서 브라우저를 클릭, 클릭 하면서 예매를 끝내주는 식이었죠.

그리고 2월에는 **'Deep Research'**가 정식 출시됐습니다. 이거 써보신 분들은 아실 거예요. 예전엔 복잡한 주제를 조사하려면 키워드를 이것저것 조합해가며 직접 검색하고, 여러 사이트를 돌아다니며 읽고, 그걸 다시 정리해서 문서로 만들어야 했잖아요. Deep Research는 그 전체 과정을 AI가 알아서 해줍니다. "이 주제로 보고서 써줘" 한 마디면 혼자 수십 개의 소스를 분석해서 정리된 보고서를 가져다주는 거죠. 지금은 Claude, Gemini, Perplexity 할 것 없이 대부분의 LLM 서비스들이 기본으로 제공하는 기능이 됐죠.

5월엔 **'Codex'**라는 코딩 에이전트의 프리뷰도 공개했는데요. 이때가 Anthropic이 Claude Code를 정식 출시했던 시기죠. Claude Code는 CLI, 로컬 환경에서 사용하는 형태였는데, 대조적으로 Codex는 클라우드 환경에서 사용하는 형태로 나왔습니다. 개인적으로는 OpenAI가 이 접근을 잘못 짚었다고 봐요. 코딩 에이전트가 제대로 일하려면 **내 컴퓨터에 이미 깔린 환경, 내 데이터, 내 설정**에 바로 접근할 수 있어야 해요. 클라우드 컨테이너에선 매번 환경을 새로 세팅해야 하니까 느릴 수밖에 없고, 저도 Codex를 처음 써봤을 때 느려서 답답하더라고요.

실제로 OpenAI도 결국 8월에 Codex CLI를 출시하면서 로컬환경에서 작업 가능하게 만들기도 했고요.

7월은 사용자 경험(UX) 측면에서 큰 변화가 있었습니다. 1월에 나온 Operator가 ChatGPT 안으로 완전히 통합됐어요. 이때부터 채팅창에 에이전트 모드가 생겼는데요. 앞서 Codex의 클라우드 방식이 아쉬웠다고 말씀드렸잖아요? 그런데 이 Operator 통합은 좀 달랐어요. 브라우저 제어처럼 **원래 클라우드에서 해야 하는 작업**을 하나의 앱, 챗GPT에서 깔끔하게 제공한 거거든요. 개발 환경처럼 로컬이 중요한 영역과, 웹 자동화처럼 클라우드가 맞는 영역 - 이 구분을 OpenAI도 조금씩 찾아가는 느낌이었습니다.

그리고 뜨거운 여름, 8월에 드디어 그 모델이 나왔습니다. GPT-5.

23년, 24년도 쯤에 기억나시나요? "GPT-5가 나오면 특이점이 온다", "AGI(일반인공지능)의 시작이다", 심지어는 "인류의 마지막 발명품이 될 거다" 하면서 전 세계가 기대 반, 두려움 반으로 엄청나게 호들갑을 떨었잖아요.

막상 뚜껑을 열어보니 터미네이터가 등장하거나 세상이 하루아침에 뒤집어지진 않았습니다. 하지만 성능은 확실히 '체급'이 달랐어요. 이전 모델들이 똑똑한 대학원생 정도였다면, GPT-5는 산전수전 다 겪은 노련한 전문가 같은 느낌을 줬거든요. 아직 AGI에 도달하진 못했지만 OpenAI가 추구하는 **'일상의 모든 것을 처리하는 AI'**가 되기에는 괜찮은 스펙이었습니다. 다시 한번 경쟁사들과의 격차를 확실하게 벌려놓은 순간이었죠.

이때 앞서 말씀드렸던 개발자용 도구인 Codex CLI도 같이 출시하면서, 앤스로픽의 텃밭인 개발자 생태계에도 본격적인 공세를 시작했습니다.

9월엔 Sora 2가 출시됐는데, 이번엔 단순한 영상 생성 웹사이트가 아니었습니다. iOS 앱으로 나오면서 마치 틱톡이나 릴스처럼 변했어요. 사람들이 텍스트로 영상을 만들고 바로 공유하는 소셜 미디어로 출시를 한거죠. 창작의 도구를 넘어선 **'놀이의 도구'**가 된 겁니다.
Sora 앱 사용중이신 분 있으신가요? 잠깐 들어가서 영상들을 보니까 뇌가 정말 녹아내린다는 느낌을 받았습니다.

10월엔 **'ChatGPT Atlas'**라는 브라우저를 공개했어요. 크롬 확장 프로그램 수준이 아니라, 그냥 브라우저 자체를 만든 건데요.

이게 왜 중요하냐면, 아까 7월에 ChatGPT에 **'에이전트 모드'**가 생겼다고 말씀드렸죠? 그 에이전트 모드가 이 Atlas 브라우저를 만나면서 진짜 완전체가 됐습니다.

검색부터 웹 서핑, 요약, 쇼핑까지 브라우저의 모든 기능을 에이전트가 직접 통제합니다. 채팅창과 브라우저의 경계가 완전히 사라지고, 브라우저 자체가 거대한 에이전트가 되는 경험을 제공했죠.

다음으로 11월은 정말 재밌는 달이었습니다. 
openai에서 gpt 5.1을 공개했는데요. 바로 며칠뒤에 구글이 Gemini 3를 발표하면서 판을 흔들어버립니다.

[구글을 의식한 트윗](https://x.com/sama/status/1990828659981144462)
샘 알트만이 쿨하게 축하 트윗을 날렸지만 실상은 코드레드 였어요. 구글 모델의 성능이 생각보다 너무 강력했거든요.

결국 12월, 한달 만에 GPT-5.2를 긴급 투입하며 맞불을 놓습니다. 보통의 시기였다면 몇 개월 걸릴 업데이트를 이렇게 단기간에 밀어붙인 걸 보면 Google의 행보에 꽤 위기의식을 느꼈다는 얘기기도 하겠죠.

그런데 이렇게 치열하게 싸우는 와중에, 다른 한편으론 '평화 협정' 같은 재미있는 이슈도 있었어요.

앞서 앤스로픽 파트에서 'MCP' 기술을 리눅스 재단(AAIF)에 기증했다고 말씀드렸죠? OpenAI도 자사의 에이전트 명세인 **AGENTS.md**를 똑같이 리눅스 재단에 기증했습니다.

그러면서 경쟁사인 앤스로픽의 'Skills' 개념을 Codex에 공식 도입하기도 했어요. 경쟁사지만 "좋은 표준은 같이 쓰자"는 거죠.

덕분에 이제 SKILL.md 파일 하나만 잘 만들어두면, 클로드한테 일을 시키든 GPT한테 시키든 똑같이 동작하는 전문 스킬을 만들 수 있게 됐습니다. 서로 치고받고 싸우면서도, **'생태계 표준'**이라는 큰 판을 위해서는 손을 잡는 모습. 참 보기 좋네요.

마지막으로 12월의 대미를 장식한 건 디즈니와의 파트너십이었습니다. 디즈니는 그동안 IP 보호에 굉장히 강경한 회사로 알려져 있었는데요.

이번에는 단순한 협업 선언이 아니라, 3년 라이선스 계약으로 Sora에서 디즈니/마블/픽사/스타워즈의 IP를 활용한 ‘팬 제작’ 숏폼 영상 생성을 공식화했습니다.

또 디즈니는 OpenAI에 10억 달러 투자를 하고, 내부적으로도 OpenAI API/ChatGPT를 활용해 제품과 워크플로우를 확장하겠다고 밝혔습니다.

- [OpenAISlide]
자, 이렇게 OpenAI의 2025년을 쭉 돌아봤는데요.

틱톡처럼 영상을 보며 노는 Sora SNS, 웹 서핑의 경험을 바꾼 Atlas 브라우저, 심지어 친구들과 다 같이 대화하는 그룹챗 기능까지도 출시했어요. 애플의 전설적인 디자이너 조니 아이브와 함께 AI 시대의 모바일 디바이스를 만들고 있다는 소식도 있죠.

OpenAI는 단순히 "똑똑한 모델"을 만드는 데 그치지 않았습니다. 우리가 놀고, 검색하고, 대화하는 모든 순간에 스며들기 위해 정말 다양한 시도를 했죠.

결국 OpenAI가 보여준 25년도는, AI가 우리 삶의 구석구석으로 퍼져나가는 **'일상의 넓이'**를 완성해가는 과정이었네요.


### [Google 행성]
자, 마지막 주자입니다. 앤스로픽이 '일의 깊이'를 파고들었고, OpenAI가 '일상의 넓이'를 장악했다면, 구글은 무엇을 보여줬을까요?

구글은 다른 회사들이 가지지 못한 무기가 있죠. 바로 전 세계 데이터가 모이는 검색 엔진, 전 세계인이 쓰는 유튜브, 그리고 안드로이드와 클라우드까지.

구글의 2025년은 이 방대한 인프라를 AI 하나로 묶어내는, 말 그대로 **"판의 크기"**를 키우는 해였습니다.

타임라인으로 따라가 볼게요.

상반기 구글의 움직임은 '기초 체력 다지기'였습니다. 2월에 Gemini 2.0 업데이트를 시작으로, 3월에는 추론 능력이 강화된 Gemini 2.5 Pro Experimental 버전을 내놓으며 경쟁사들의 기술 속도를 부지런히 따라잡았죠.

4월엔 작년에 팟캐스트 기능으로 대박이 났던 NotebookLM이 한 번 더 진화했어요. 

NotebookLM을 간단히 설명해 드리자면, 내가 가진 수많은 PDF, 논문, 회의록, 기획 문서들을 업로드 하고 질문을 하면 생성형 AI가 이 내용 안에서만 답변을 해주는 RAG 기반의 노트 앱입니다.

이 NotebookLM의 오디오 오버뷰가 무려 50개 언어를 지원하게 됐어요. 어떤 자료든 넣기만 하면 내가 원하는 언어로 팟캐스트를 들을 수 있게 된거에요. 영어 자료들, 어려워서 보기 힘들었던 논문들을 다 때려박고 이 내용들을 요약하는 팟캐스트를 클릭 한번에 만들게 됐습니다.

그리고 5월, 구글의 개발자 축제 Google I/O에서 첫 번째 '한 방'이 터졌습니다.

바로 **'Veo 3'**와 **'Imagen 4'**의 공개였어요. 특히 Veo 3가 충격적이었는데요. 이전까지 비디오 생성 AI들은 많았어요. 영상은 잘 만들었지만 소리가 없거나, 효과음을 따로 입혀야 했잖아요? Veo 3는 세계 최초로 네이티브 오디오를 포함한 영상을 생성했습니다. 영상 속 강아지가 짖으면 그 소리가 동시에 생성되는 거죠. 이때부터 멀티모달 분야, 특히 미디어 생성에서는 구글이 확실한 우위를 점하기 시작합니다.

**Google AI Studio**도 진화했는데요. 원래는 API 테스트용 플레이그라운드였는데, 이제 자연어만으로 웹앱까지 만들 수 있는 빌더가 됐어요.

6월엔 Gemini CLI를 내놓으며 에이전트 시장에 발도 담갔고요. 클로드 코드나 코덱스 같은 걸 만든거에요.

7월엔 NotebookLM이 이제 오디오를 넘어 '비디오 오버뷰'까지 만들어주기 시작했습니다. 문서를 넣으면 강의 영상을 만들어줘요.
잠깐 영상 한 번 볼까요.

8월엔 이름도 귀여운 'Nano Banana(나노 바나나)' 모델이 나왔습니다.
사진 속 불필요한 사람을 지우거나 표정을 바꾸는 걸 아주 가볍고 빠르게 처리해줘서 화제가 됐죠. 

10월엔 Veo 3.1 업데이트로 영상 생성 모델의 급이다른 클래스를 보여주더니

그리고 11월엔 내용이 꽤 많습니다.
Gemini 3가 출시 됐어요. 아까 OpenAI 파트에서 샘 알트만이 축하 트윗을 날리고 뒤로는 비상이 걸렸었다는 그 시점입니다. Gemini 3.0은 출시되자마자 각종 벤치마크를 휩쓸며 "역시 기술의 구글이다"라는 소리를 다시 듣게 만들었습니다.

솔직히 Gemini 2.0, 2.5는 제가 경험했을 땐 별로였었거든요. 근데 Gemini 3는 아 이제 다 따라잡았구나 싶더라구요.

또 개발자를 위한 깜짝 선물도 있었습니다. 바로 **'Antigravity'**인데요.

구글이 전 세계 개발자들의 표준 툴인 VSCode를 기반으로, 자신들만의 **'에이전트 전용 IDE'**를 출시했어요. 이름이 참 재밌죠? 'Antigravity', 반중력입니다.

개발자들을 짓누르던 환경 설정, 배포, 운영 같은 무거운 '중력'을 AI가 대신 들어주겠다는 뜻이에요.

이게 말뿐이 아닌 게, MCP로 구글 클라우드와 완벽하게 연동됩니다. 내가 핵심 코드를 짜는 동안, 에이전트는 뒤단에서 알아서 서버를 띄우고, 데이터베이스를 연결하고, 배포까지 준비합니다. 개발부터 인프라 운영까지, AI에게 믿고 맡기는 진정한 **'반중력'**의 세계가 열린 거죠.

Nano Banana를 더 업그레이드한 Nano Banana Pro도 출시 했고요. 이제 포토샵이 필요 없어요. 설명하는대로 타이포그래피부터 레이아웃 디자인까지 전문가 수준으로 뽑아줍니다. 디자이너의 손길이 필요했던 섬세한 작업들까지 AI의 영역으로 들어온 거죠.

그리고 여기서 구글은 한 발 더 나아가 **'Generative UI'**라는 새로운 패러다임도 제시했어요.

이게 뭐냐면요, 우리가 지금까지 AI랑 대화할 땐 주로 '텍스트'로만 주고받았잖아요? 근데 이제는 AI가 내 질문에 가장 적합한 **'UI(화면)'**를 그 자리에서 즉석으로 만들어줍니다.

예를 들어 "도쿄 여행 계획 짜줘"라고 하면, 단순히 줄글로 알려주는 게 아니라, 지도에는 핀이 찍혀있고, 아래엔 타임라인 슬라이더가 있고, 옆에는 예산 계산기가 달린 **'미니 앱'**을 채팅창에 짠하고 띄워주는 식이죠.

이 'Generative UI' 기술이 적용된 결정체가 바로 12월에 나온 **'Gen Tabs'**입니다.

이건 우리가 알던 브라우저의 '탭' 개념을 바꿨어요. 내가 검색하고 쇼핑하던 여러 탭들을 AI가 실시간으로 분석해서 하나의 동적인 대시보드로 합쳐서 보여주는 거죠. '생성형 UI' 기술의 정점을 보여준 거에요.


- [GoogleSlide]
자, 이렇게 25년도 구글의 행보를 요약해보면 **"AI Universe(AI 유니버스)의 완성"**이라고 할 수 있겠네요.

구글은 자신들이 가진 가장 강력한 무기인 **'검색-워크스페이스-클라우드'**를 AI 하나로 묶어냈습니다. 머리에는 Gemini 3라는 압도적 두뇌를, 손에는 Antigravity IDE라는 최고의 도구를 쥐어주면서, 사용자가 굳이 밖으로 나갈 필요가 없는 거대한 **'빈틈없는 생태계(Seamless Ecosystem)'**를 이뤄낸 거죠.

특히 가장 큰 임팩트는 Gemini 3.0이 LMArena 1500점을 돌파한 순간이었죠. 이 압도적인 성능의 비결은 구글의 자체 AI 칩, **TPU**에 있습니다.

남들이 비싼 GPU 비용으로 고민할 때, 구글은 직접 만든 이 칩을 통해 성능과 에너지 효율을 비약적으로 개선했다고 해요. 덕분에 비용 걱정 없이 가장 똑똑한 AI 모델을 가장 빠르고 저렴하게 돌릴 수 있는, **'인프라의 초격차'**를 증명해냈습니다. 

이외에도 구글은 다양한 실험들을 [GoogleLabs](https://labs.google/)에서 진행하고 있어요. 재밌는 제품들이 많아서 꼭 한번 들어가보시는 걸 추천합니다.

- [ThreeGiantsSummarySlide]
자, 여기까지 25년을 숨 가쁘게 달려온 세 거인, Anthropic, OpenAI, Google의 1년간 타임라인을 정리해봤습니다.

**'일의 깊이'**를 파고든 앤스로픽, **'일상의 넓이'**를 장악한 OpenAI, 그리고 압도적인 인프라로 **'판의 크기'**를 키운 구글까지.

서로 다른 비전을 가지고 달려온 이들의 경쟁 덕분에, 우리는 1년 전과는 비교할 수 없는 완전히 새로운 AI 생태계를 마주하고 있네요.


## 3. 대담 - 활용 사례

### Anthropic - Claude Code
- [ClaudeCodeIntroSlide]
Anthropic에서 올해 가장 파괴적이었던 제품을 꼽으라면 단연 Claude Code입니다. 오늘 제가 여러분께 가장 강조하고 싶은 도구이기도 해요.

사실 '코딩'이라는 단어 때문에 "아, 저건 개발자 형님들 도구구나" 하고 넘어가기 쉬운데요. [Anthropic 내부 팀들의 사례](https://claude.com/blog/how-anthropic-teams-use-claude-code)를 보면 마케팅, 운영, 인사팀에서도 이걸로 업무 효율을 몇 배씩 올리고 있습니다.

- [ClaudeCodeWhySlide]

우리가 업무를 할 때 쓰는 노션, 엑셀, 피그마 같은 툴들은 결국 '특정한 목적'을 위해 만들어진 박제된 프로그램입니다. 하지만 Claude Code를 쓰면 **'내 업무에 딱 맞는 툴'**을 그 자리에서 즉석으로 만들어서 결과까지 뽑아낼 수 있어요.

이게 가능한 이유는 Claude Code가 단순히 코드를 짜는 게 아니라, 내 컴퓨터 안에서 **'실제로 움직이는 손과 발'**을 가졌기 때문입니다.

거기에 개발자들이 일하는 방식인 Git 협업까지 더해지면, 히스토리는 알아서 쌓이고, 모든 컨텍스트를 내 손으로 관리할 수 있습니다. 노션이나 지라 없이도요.

물론 러닝커브가 좀 있고, Claude Code에 의존성이 생긴다는 단점도 있습니다. 그래도 오늘 이런 에이전틱 워크플로우가 있구나, 아이디어만 얻으셔도 언젠가 도움이 되는 날이 올거라고 생각해요.

- [ClaudeCodeWhatSlide]
Anthropic에서 만든 CLI 기반의 코딩 에이전트 입니다. 자연어로 요청하면 혼자 플랜을 짜고, 복잡한 코드를 알아서 작성하고, 파일까지 생성해요.

뭔가 Claude라는 서비스도 있고 Claude Code라는 서비스도 있으니까 헷갈릴 수 있는데 Claude Code라는 터미널에서 사용하는 프로그램이고 내부적으로 클로드를 호출해서 사용한다! 정도로 이해하시면 됩니다.

- [ClaudeCodePrincipleSlide]
챗GPT나 클로드 같은 LLM, AI 언어 모델은 본래 "텍스트"를 생성하는 것만 할 수 있어요. 순수한 언어 모델한테 "코드 작성하고 파일로 만들어줘" 같은 요청을 하면 할 수 없는 일이라고 답변할거에요.

그런데 클로드 코드 라는 프로그램은 직접 파일을 읽고, 프로젝트를 파악하고 수정도 할 수 있습니다. 순수한 언어모델이 어떻게 외부의 세상과 소통할 수 있는걸까요? 대체 이게 어떻게 가능한걸까요?

- [ToolUseSlide]
비밀은 도구(Tool)에 있습니다.
`claude-code-flow.svg`

예를 들어서 "기획서 바탕으로 웹 페이지 만들어줘"라고 요청하면

클로드 코드라는 프로그램이 나의 요청과 함께, 사용 가능한 도구 목록을 언어 모델에게 보냅니다.
언어 모델은 "ReadFile: docs/project-plan.md" 라고 응답해요.
그럼 클로드 코드라는 프로그램은 어떤 응답이 오면 이런이런 코드를 실행해라~ 같은 규칙이 있겠죠.
그렇게 실제로 파일을 읽어서 내용을 언어 모델에게 다시 전달합니다.
언어 모델은 내용을 보고 "WriteFile: app/dashboard/page.tsx" + 페이지 코드를 응답합니다.
클로드 코드가 실제로 페이지 파일을 생성합니다.
언어모델이 외부 세상과 상호작용할 수 있게 하는 꽤 영리한 방법이죠?

실제로 클로드 코드를 사용하다 보면 Read(README.md) Write(page.tsx) 같은 응답들이 보일거에요.

"클로드 코드 사용법"에 대한 더 자세한 내용은 [클로드 코드 가이드](https://ai-landscape-2025.vercel.app/claude-code)를 참고하시죠.

- [Claude Code 화면 직접 보여드리기]
Claude Code를 잠깐 보여드리자면
`현재 프로젝트가 어떤 프로젝트지?  입력`

내 프로젝트가 어떤 건지, Context를 파악하고 있다는 건 정말 큰 장점이죠.

- [ClaudeFolderSlide]
그리고 내가 진행하는 프로젝트에 대해 AI한테 정보를 줘야하거나, 업무를 진행하면서 반복적으로 하게 되는 작업이 있을거에요.

그럴 때 .claude 라는 폴더만 만들고, 우리가 익숙한 폴더 디렉토리 형태로 구조화 하면서, 필요한 사항들을 마크다운으로 명세만 잘하면, 이거 자체가 llm한테 주는 context이자 내 프로젝트에 대한 전반적인 세팅이 되버립니다.

내 프로젝트에 맞춤형으로 되어 있는 세팅, .claude 폴더가 어떻게 구성되는지 이해하시면 25년도의 주요했던 키워드인 에이전트가 어떤 느낌인지도 파악하실 수 있어요.

- [ContextDeskSlide]

```
당신은 스타트업에 입사한 신입 (Claude)
- CLAUDE.md = 사원증에 적힌 직급/권한
- Skills = 매뉴얼들 (필요할 때 꺼내봄)
- Subagents = 협업 요청하는 다른 팀 (슬랙으로 던지고 결과만 받음)
- MCP = 회사가 쓰는 외부 SaaS들 (Notion, Slack, Jira 등 다른 서비스 연동)
- Context, Context Window = 내 책상의 공간
```

먼저 CLAUDE.md 파일입니다. "이 프로젝트에서 이렇게 일해"라는 최상위 규칙이에요. 프로젝트의 시스템 프롬프트라고 할 수도 있죠.

그리고 Subagents 혹은 agents라고 부르는데, 복잡한 일은 외주를 줄 사람들을 작성해놓는거에요.
agents 폴더 하위에 마크다운으로 어떤 일을 시킬 프리랜서인지 명세를 해요.
그럼 필요한 작업이 있을 때 내가 미리 명세한대로 에이전트한테 일을 시켜요.

이게 왜 중요하냐. llm을 쓸 때 context window라고 해서 한번에 볼 수 있는 정보량이 정해져 있습니다. 책상크기라고 생각하시면 돼요. 복잡한 일을 시키면 책상 위에 서류가 쌓이잖아요? 그러다 보면 정작 중요한 게 묻혀 버려요.

그런데 Subagent는 내 책상을 어지럽히지 않고, 별도의 책상에서 일하고 작업한 결과만 딱 정리해서 갖다줍니다. 내 책상은 깔끔하게 유지되고요.

저는 slide를 디자인 해주는 slide-designer라는 에이전트를 만들고 활용했어요.

다음은 Skills입니다.
자주 하는 업무가 있으면 매뉴얼로 만들어두잖아요? Skills가 그거예요.
근데 매뉴얼을 항상 책상 위에 펼쳐놓진 않잖아요. 서랍에 넣어뒀다가, 필요할 때만 꺼내보죠.

Skills도 똑같아요. 평소엔 context를 차지하지 않다가, "이 작업 해줘"라고 하면 그때 해당 매뉴얼만 꺼내서 읽어요.

그래서 Skills를 많이 만들어도 책상은 깔끔해요. 필요한 것만 필요한 순간에만 꺼내서 읽으니까요. 이렇게 만든 Skill은 Subagent한테 전달해줄 수도 있습니다.

저는 design스킬을 만들어서 slide-design에 대한 톤앤매너를 미리 설정 해두고, 이 스킬을 아까의 slide-designer가 사용하게 했어요.

결국 skill도 agent도 context, 내 작업공간을 어떻게 효율적으로 관리할거냐에서 시작하는거라고 생각하시면 됩니다.

그리고 마지막, MCP입니다.
클로드 코드에서 외부의 서비스랑 연동되게 하고 싶어요. 그럴 때 사용하는게 MCP입니다.

저는 주로 Codex MCP나 Replicate MCP를 활용하는데요.
클로드 코드 인터페이스에서 Codex를 예로 보여드릴게요.

`codex 안녕`

그럼 이런 claude.md, agent, skill, mcp 같은 것들 다 직접 작성하냐. 아뇨 이것도 다 claude한테 시킵니다. 이런것들을 만들어주는 skill이 빌트인 되어 있어요. 나는 발전시키는 과정에서 조금씩만 개입을 하면돼요.

자 이렇게 **"우리 팀은 이런 식으로 일해"**라고 마크다운(Markdown) 문서와 폴더 구조를 만들기만 하면 나머지는 Claude가 이 문서를 읽고 '눈치껏' 일해주는 겁니다.


- [LivePicksSlide]
### OpenAI
일상에서 언어 공부할 때, Voice Mode는 OpenAI가 젤 잘하는 듯.

### Google - Antigravity, NotebookLM, NanoBanana


## 4. 질의응답


## 마무리
[Thinking about Thinking](https://www.youtube.com/watch?v=d95J8yzvjbQ&t=4901s)

[고졸 OpenAI Engineer](https://www.youtube.com/watch?v=vq5WhoPCWQ8)

[바이브 코딩](https://x.com/karpathy/status/1886192184808149383)

[LLM한테 “너는 어떻게 생각해?”라고 묻지 마세요](https://x.com/karpathy/status/1997731268969304070)

[Context Engineering](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)

[Agents](https://agents.md/)
https://aaif.io/

SOTA 관련 - 한번의 경험에 머물러 있지 않는 마인드셋

https://labs.google/ -> 구글 실험 진짜 많이 함



# 세션 흐름

## 0. 인트로 (주형 발표)

생성형 AI, 이제는 우리의 업무와 일상에서 빼놓을 수 없습니다.
워낙 많은 관심을 받고 있는 분야라 그런지 발전하고 있는 속도도 빠르고
한번 소식을 가까이 하고 있지 않으면 쌓이는 새로운 소식들을 따라잡는게 어려워지더라구요.

이런 너무나도 빠른 세상에 뒤쳐지고 싶지 않아서 
저는 이런 AI 트렌드를 자주 접하고 있는데요.
이런 AI 소식들을 동료분들한테 쉽게 요약하고 공유하는 걸 좋아합니다.

그렇게 실제로 동료분들의 업무에 도움이 될 때 꽤 뿌듯하더라구요.

오늘 준비한 내용이 여러분들께도 도움이 되기를 바라면서
2025년 생성형 AI 트렌드 총 정리 시작해보겠습니다.

## 1. 키워드
- [키워드들 둥실 슬라이드] 
`Reasoning Mode, 컨텍스트 엔지니어링, 나노바나나 veo, 바이브 코딩, 에이전트`

자 먼저 올해 생성형 AI분야에서 핫했던 키워드들부터 이야기해볼게요.

- [사고 과정 채팅창에 표현된 스샷]
첫번째 키워드는 Reasoning Model입니다.
사실 24년 하반기부터 조금씩 모습을 드러냈는데, 25년도가 되면서 비즈니스 현장에 본격적으로 확산되기 시작했어요. 이 모델들의 가장 큰 특징을 꼽으라면, **'답을 내기 전에 더 오래 생각한다'**는 점이에요. 
이전 llm 모델들이 질문을 받으면 비교적 빠르게 계산을 마친 뒤 결과를 던져줬다면, reasoning 모델은 계획을 세우고 → 추론하고 → 중간에 스스로 검증하는 단계를 더 강하게 거칩니다.
한마디로 “정답만 내는 AI”에서 **“생각하고 검산하는 AI”**로 진화한 거죠.

이게 왜 중요하냐면요, 생성형 AI가 스스로 문제를 해결하는 경로를 설계하고 그 과정에서 생기는 논리적 오류를 스스로 검토할 수 있게 됐어요. 

예전에는 사용자가 직접 Chain of Thought 같은 프롬프팅 기법으로 유도하던걸, 이제는 모델이 기본값으로 그런 식의 사고 루틴을 더 잘 수행하도록 만들어진거죠. 덕분에 복잡한 기획안 작성이나 고도의 코딩 작업처럼 '논리적 완결성'이 필요한 업무에서 이전과는 비교할 수 없는 성능을 보여주게 됐습니다.

이렇게 AI가 스스로 논리를 짜기 시작하니까, 우리에게는 또 다른 숙제가 생겼어요. 

AI가 제대로 판단할 수 있게 필요한 재료들을 잘 넣어줘야겠죠? 그게 바로 두 번째 키워드, "컨텍스트 엔지니어링"입니다.

- [컨텍스트 엔지니어링 예시 화면/짤 하나]
방금 이야기한 reasoning 모델이 “생각하고 검산하는 AI”라면요, 이제부터는 그 AI가 생각할 ‘재료’를 우리가 어떻게 주느냐가 성능을 좌우하기 시작했어요.
쉽게 말해서, 프롬프트 엔지니어링이 '질문을 어떻게 예쁘게 할까'를 고민하는 기술이었다면, 컨텍스트 엔지니어링은 생성형 AI에게 **'어떤 정보를, 어떤 순서로 줄까'**를 설계하는 기술입니다. 모델이 똑똑해진 만큼, 질문 한 줄보다는 참고할 문서, 히스토리, 제약 조건 같은 **'맥락,Context'**를 얼마나 잘 구조화해서 던져주느냐가 결과물의 퀄리티를 결정하게 된 거죠.

- [나노바나나]
또 올해는 이미지나 비디오 생성에서도 뛰어난 발전을 보여줬던 해입니다. 이건 세션 후반부의 Google 파트에서 더 알아볼게요.

- [에이전트]
그리고 이 모든 키워드들이 모이는 종착역, **Agent(에이전트)**입니다.
아마 올해 가장 많이 들으셨을 단어일거에요.
24년도엔 생성형 AI가 똑똑한 비서, "어시스턴트"라고 불렸다면 
올해는 생성형AI가 에이전트라고 많이 불렸습니다.

어떻게 보면 생성형 AI의 성능이 올라오고, 해결할 수 있는 일이 많아져서 그런지 
지위가 비서에서 동료로 승진을 했죠.

그렇게 25년도 생성형 AI는 우리 곁의 '동료'가 되었습니다. 

이런 AI 에이전트는 코드를 짜고 혼자 빌드해서 테스트도 해보고 개발자가 하는 일들을 완전히 대체할 수 있어요. 내가 개발을 모르더라도 코딩을 할 수 있으니, 심지어는 "바이브코딩"이라는 단어도 유행하게 됐고요. 이 바이브 코딩은 결국 사전에 등재까지 됐습니다.

현재는 ai 에이전트가 브라우저를 직접 조작하는것 까지도 가능해요.

이제 '혼자서 일하는 AI'의 시대가 열렸다고 할 수 있겠네요.

이렇게 키워드로만 봐도 25년이 얼마나 정신없었는지 느껴지시죠? 그런데 재밌는 건, 이 '에이전트'라는 똑같은 목표를 보고 달려가는데 Anthropic, OpenAI, Google 세 회사의 스타일이 완전히 달랐어요.

한 곳은 **'개발자의 손'**을 대신하려 했고, 한 곳은 **'우리의 일상'**을 점유하려 하고, 한 곳은 **'세상의 모든 인프라'**를 AI로 장악하려고 했습니다.

## 2. 3사 타임라인별 쭉 흐름 가볍게 리뷰
- [3사 컨셉 요약]
  - Anthropic: "일의 깊이"
  - OpenAI: "일상의 넓이"
  - Google: "판의 크기"

Anthorpic, OpenAI, Google의 전략을 요약해보자면 요런 느낌이에요.
Antrhopic은 "일의 깊이"에 집중했고요. OpenAI는 "일상의 넓이"를 택했습니다. Google은 구글이 가진 방대한 인프라를 활용해서 "판의 크기"를 키우려고 했고요.

자 그럼 25년 동안 Anthropic, OpenAI, Google 이 세 거인이 어떤 발자취를 남겼는지, 월별 타임라인을 통해 자세히 살펴보겠습니다. 모델이 출시된 내용은 가볍게 넘어갈게요.

[Antrhopic 행성]

먼저 Antrhopic입니다.
Anthropic에선 2월에 Claude 3.7 Sonnet이라는 모델 발표와 함께
Claude Code라는 터미널 기반의 코딩 에이전트를 research preview 형태로 출시했어요.

이 당시에 Cursor, Windsurf, Lovable 같은 툴들이 에이전틱 코딩을 하기위해 많이 유행하던 상태였는데요.

Cursor에서 Claude 모델들을 호출해서 잘 쓰고 있는데 왜 굳이? CLI를? 
처음엔 사람들의 반응도 의아했어요. 그런데 Anthropic이 이렇게 설계한 이유는 사내 개발자들이 사용하는 코드 에디터가 너무 다양하다보니 모두가 쓸 수 있는 방법을 찾다가 CLI 형태가 됐다고 합니다. 어떤 컴퓨터든 기본적으로 있는게 터미널이니까요.

Claude Code를 잘 활용하면 지금 보이는 이런 웹사이트를 코딩을 몰라도 자연어로 만들 수가 있습니다.
이 클로드 코드 출시는 꽤 중요했던 내용이라 3사별 주요 이슈에서 더 자세히 알아보겠습니다.

3월엔 24년도에 Anthropic에서 발표한 MCP를 OpenAI에서 공식적으로 채택했던 것도 3월이었어요.
그리고 경쟁사 대비 다소 늦은편이었지만 웹 검색기능이 클로드에 출시 됐습니다. 이젠 어떤 걸 써도 다 있는 기능이죠. 프롬프트에 "웹 검색해줘"라고 입력만 하면 알아서 검색을 대신해줍니다.

5월에 Claude Code가 정식으로 출시 됐습니다.
이 때 개발자들이 제일 많이 쓰는 VSCode, IntelliJ에 플러그인 형태로 사용할 수도 있게 공식으로 지원하기 시작했어요.

8월엔 Claude for Chrome Research Preview를 발표했는데요.
크롬에서 클로드를 확장 프로그램 형태로 사용하는 툴입니다.

클로드 코드와 클로드 for chrome만 봐도 Anthropic은 플랫폼에 종속되지 않고 누구나 쉽게 접할 수 있게 제품들을 출시하려는게 보이네요.

그리고 9월엔 Excel, PPT, PDF를 생성하는 파일 생성 기능이 클로드에 출시 됐습니다.
자연어 만으로 진짜 내가 업무에 필요한 파일들을 짠하고 만드는게 가능해진 거죠.

여기서 놀라운건 10월에 발표된 Claude Skills인데요. 
9월에 출시된 파일생성 기능이 Skills로 만들어졌다고 해요.

Skills는 "저런 파일 생성 기능"을 누구나 쉽게 받아들일 수 있는 우리 컴퓨터에서의 폴더 디렉토리 형태로 구조만 짜면 Claude가 도메인에 특화된 전문적인 작업들을 가능케 해주는 기능이었습니다. 이것도 꽤 중요한 내용이에요.

11월엔 Microsoft의 Excel 프로그램에 빌트인해서 쓸 수 있는 Claude in Excel도 베타로 발표했습니다.

그리고 요번달이죠. 12월엔 내용이 꽤 많습니다.

먼저 Claude Code가 정식 출시된지 6개월만에 1조원의 매출을 달성했다고 합니다. 진짜 어마어마한 수치죠. 이것만 봐도 Anthropic에게 Claude Code가 얼마나 중요한 제품이었는지, 사람들이 얼마나 열광했는지 알 수 있네요.

슬랙으로 사용하는 Claude Code가 나오고 베타로 있던 Claude for Chrome, 크롬 확장자가 정식 출시 됐습니다.

이제 크롬에서 저 확장자만 설치하면 혼자 일을 해요. 아직은 쪼금 느린 감이 있지만 그래도 내가 워크플로우만 잘 설명하고 녹화하면 이전엔 수동으로 해야했던 일을 자동으로 처리합니다.

Claude for Chrome도 앞으로 꽤 중요한 내용이 될거에요.
단순히 브라우저에서 채팅 인터페이스가 필요한 순간에만 사용하는 게 아니라,
Claude Code와 함께 활용하면서 브라우저를 제어하는게 가능하거든요. 

마지막으로 12월엔 앤스로픽이 자사의 MCP 기술을 리눅스 재단(AAIF)에 전격 기증했습니다. 이건 마치 인터넷의 HTTP처럼, AI 에이전트가 각종 소프트웨어와 소통하는 방식을 **'전 세계 표준'**으로 만들겠다는 선언이에요. 특정 기업의 소유물이 아니라 모두가 쓰는 공용어가 되어야 생태계가 폭발적으로 커질 수 있으니까요. 결국 기술 독점보다는 **'표준 선점'**을 통해 에이전트 시대의 가장 기초적인 뼈대를 앤스로픽의 방식대로 구축하겠다는 큰 그림인 셈입니다.

자, 이렇게 앤스로픽의 25년도를 돌아보면 한 가지 확실한 철학이 보입니다. 이들은 클로드라는 AI를 채팅창 안에 가두지 않았어요. 개발자의 검은 터미널 화면(CLI)부터, 슬랙 사내메신저, 마케터의 크롬 브라우저, 재무팀의 엑셀까지... 우리가 **'일하는 모든 현장'**으로 직접 찾아왔습니다. 결국 앤스로픽은 특정 플랫폼을 만드는 것을 넘어, **'어떤 환경에서든 작동하는 업무의 표준 인터페이스'**가 되는걸 전략적으로 접근하고 있어요. 초보자에게는 쉬운 접근성을, 전문가에게는 날개를 달아주는 도구. 그게 바로 앤스로픽이 보여준 **'일의 깊이'**였습니다.


---

[OpenAI 행성]
자, 앤스로픽이 '일 잘하는 동료'였다면, 이번엔 OpenAI입니다. OpenAI의 2025년은 한마디로 **"우리의 일상을 점령하러 왔다"**고 표현할 수 있겠네요.

앤스로픽이 개발자 도구나 업무용 툴에 집중할 때, OpenAI는 소비자들이 피부로 느낄 수 있는 서비스와 디바이스, 그리고 브라우저 영역으로 전략적인 접근을 했습니다.

타임라인으로 한번 볼게요.

가장 먼저 1월, **'Operator'**를 research preview로 출시하며 새해 포문을 열었습니다. 기존에 우리가 컴퓨터를 쓸 때 마우스로 클릭하고, 타이핑하던 걸 AI가 대신해주는 '브라우저 제어 에이전트'인데요. 앤스로픽이 24년도에 'Computer Use'라는 기능을 출시 했었어요. 거기에 대응해서 만든 기능이라고 생각하시면 되고 "비행기 표 예매해줘"라고 하면 내가 보는 앞에서 브라우저를 클릭, 클릭 하면서 예매를 끝내주는 식이었죠.

그리고 2월에는 **'Deep Research'**가 정식 출시됐습니다. 이거 써보신 분들은 아실 거예요. 예전엔 복잡한 주제를 조사하려면 키워드를 이것저것 조합해가며 직접 검색하고, 여러 사이트를 돌아다니며 읽고, 그걸 다시 정리해서 문서로 만들어야 했잖아요. Deep Research는 그 전체 과정을 AI가 알아서 해줍니다. "이 주제로 보고서 써줘" 한 마디면 혼자 수십 개의 소스를 분석해서 정리된 보고서를 가져다주는 거죠. 지금은 Claude, Gemini, Perplexity 할 것 없이 대부분의 LLM 서비스들이 기본으로 제공하는 기능이 됐죠.

5월엔 **'Codex'**라는 코딩 에이전트의 프리뷰도 공개했는데요. 이때가 Anthropic이 Claude Code를 출시했던 시기죠. Claude Code는 CLI, 로컬 환경에서 사용하는 형태였는데, 대조적으로 Codex는 클라우드 환경에서 사용하는 형태로 나왔습니다. 개인적으로는 OpenAI가 이 접근을 잘못 짚었다고 봐요. 코딩 에이전트가 제대로 일하려면 **내 컴퓨터에 이미 깔린 환경, 내 데이터, 내 설정**에 바로 접근할 수 있어야 해요. 클라우드 컨테이너에선 매번 환경을 새로 세팅해야 하니까 느릴 수밖에 없고, 저도 Codex를 처음 써봤을 때 느려서 답답하더라고요.

실제로 OpenAI도 결국 8월에 Codex CLI를 출시하면서 로컬환경에서 작업 가능하게 만들기도 했고요.

7월은 사용자 경험(UX) 측면에서 큰 변화가 있었습니다. 1월에 나온 Operator가 ChatGPT 안으로 완전히 통합됐어요. 이때부터 채팅창에 에이전트 모드가 생겼는데요. 앞서 Codex의 클라우드 방식이 아쉬웠다고 말씀드렸잖아요? 그런데 이 Operator 통합은 좀 달랐어요. 브라우저 제어처럼 **원래 클라우드에서 해야 하는 작업**을 하나의 앱, 챗GPT에서 깔끔하게 제공한 거거든요. 개발 환경처럼 로컬이 중요한 영역과, 웹 자동화처럼 클라우드가 맞는 영역 - 이 구분을 OpenAI도 조금씩 찾아가는 느낌이었습니다.

그리고 뜨거운 여름, 8월에 드디어 그 모델이 나왔습니다. GPT-5.

사실 23년, 24년도 쯤에 기억나시나요? "GPT-5가 나오면 특이점이 온다", "AGI(일반인공지능)의 시작이다", 심지어는 "인류의 마지막 발명품이 될 거다" 하면서 전 세계가 기대 반, 두려움 반으로 엄청나게 호들갑을 떨었잖아요.

막상 뚜껑을 열어보니 터미네이터가 등장하거나 세상이 하루아침에 뒤집어지진 않았습니다. 하지만 성능은 확실히 '체급'이 달랐어요. 이전 모델들이 똑똑한 대학원생 정도였다면, GPT-5는 산전수전 다 겪은 노련한 전문가 같은 느낌을 줬거든요. 아직 AGI에 도달하진 못했지만 OpenAI가 추구하는 **'일상의 모든 것을 처리하는 AI'**가 되기에는 차고 넘치는 스펙이었습니다. 다시 한번 경쟁사들과의 격차를 확실하게 벌려놓은 순간이었죠.

이때 앞서 말씀드렸던 개발자용 도구인 Codex CLI도 같이 출시하면서, 앤스로픽의 텃밭인 개발자 생태계에도 본격적인 공세를 시작했습니다.

9월엔 Sora 2가 출시됐는데, 이번엔 단순한 영상 생성 웹사이트가 아니었습니다. iOS 앱으로 나오면서 마치 틱톡이나 릴스처럼 변했어요. 사람들이 텍스트로 영상을 만들고 바로 공유하는 소셜 미디어로 출시를 한거죠. 창작의 도구를 넘어선 **'놀이의 도구'**가 된 겁니다.
Sora 앱 사용중이신 분 있으신가요? 잠깐 들어가서 영상들을 보니까 뇌가 정말 녹아내린다는 느낌을 받았습니다.

10월엔 **'ChatGPT Atlas'**라는 브라우저를 공개했어요. 크롬 확장 프로그램 수준이 아니라, 그냥 브라우저 자체를 만든 건데요.

이게 왜 중요하냐면, 아까 7월에 ChatGPT에 **'에이전트 모드'**가 생겼다고 말씀드렸죠? 그 에이전트 모드가 이 Atlas 브라우저를 만나면서 진짜 완전체가 됐습니다.

남의 브라우저인 크롬에서 확장 프로그램으로 돌아갈 때랑은 차원이 달라요. 검색부터 웹 서핑, 요약, 쇼핑까지 브라우저의 모든 기능을 에이전트가 직접 통제합니다. 채팅창과 브라우저의 경계가 완전히 사라지고, 브라우저 자체가 거대한 에이전트가 되는 경험을 제공했죠.

11월은 정말 재밌는 달이었습니다. 
openai에서 gpt 5.1을 공개했는데요. 바로 며칠뒤에 구글이 Gemini 3를 발표하면서 판을 흔들어버립니다.

[구글을 의식한 트윗](https://x.com/sama/status/1990828659981144462)
샘 알트만이 쿨하게 축하 트윗을 날렸지만 실상은 코드레드 였어요. 구글 모델의 성능이 생각보다 너무 강력했거든요.

결국 12월, 한달 만에 GPT-5.2를 긴급 투입하며 맞불을 놓습니다. 보통의 시기였다면 몇 개월 걸릴 업데이트를 이렇게 단기간에 밀어붙인 걸 보면 Google의 행보에 꽤 위기의식을 느꼈다는 얘기기도 하겠죠.

그런데 이렇게 치열하게 싸우는 와중에, 다른 한편으론 '평화 협정' 같은 재미있는 이슈도 있었어요.

앞서 앤스로픽 파트에서 'MCP' 기술을 리눅스 재단(AAIF)에 기증했다고 말씀드렸죠? OpenAI도 자사의 에이전트 명세인 **AGENTS.md**를 똑같이 리눅스 재단에 기증했습니다.

그러면서 경쟁사인 앤스로픽의 'Skills' 개념을 Codex에 공식 도입하기도 했어요. 경쟁사지만 "좋은 표준은 같이 쓰자"는 거죠.

덕분에 이제 SKILL.md 파일 하나만 잘 만들어두면, 클로드한테 일을 시키든 GPT한테 시키든 똑같이 동작하는 전문 스킬을 만들 수 있게 됐습니다. 서로 치고받고 싸우면서도, **'생태계 표준'**이라는 큰 판을 위해서는 손을 잡는 모습. 참 보기 좋네요.

마지막으로 12월의 대미를 장식한 건 디즈니와의 파트너십이었습니다. 디즈니는 그동안 IP 보호에 굉장히 강경한 회사로 알려져 있었는데요.

이번에는 단순한 협업 선언이 아니라, 3년 라이선스 계약으로 Sora에서 디즈니/마블/픽사/스타워즈의 IP를 활용한 ‘팬 제작’ 숏폼 영상 생성을 공식화했습니다.

또 디즈니는 OpenAI에 10억 달러 투자를 하고, 내부적으로도 OpenAI API/ChatGPT를 활용해 제품과 워크플로우를 확장하겠다고 밝혔습니다.


자, 이렇게 OpenAI의 2025년을 쭉 돌아봤는데요.

틱톡처럼 영상을 보며 노는 Sora SNS, 웹 서핑의 경험을 바꾼 Atlas 브라우저, 심지어 친구들과 다 같이 대화하는 그룹챗 기능까지도 출시했어요. 애플의 전설적인 디자이너 조니 아이브와 함께 AI 시대의 모바일 디바이스를 만들고 있다는 소식도 있죠.

OpenAI는 단순히 "똑똑한 모델"을 만드는 데 그치지 않았습니다. 우리가 놀고, 검색하고, 대화하는 모든 순간에 스며들기 위해 정말 다양한 시도를 했죠.

결국 OpenAI가 보여준 25년도는, AI가 우리 삶의 구석구석으로 퍼져나가는 **'일상의 넓이'**를 완성해가는 과정이었네요.


[Google 행성]


Google은 ~~

## 3. 3사에서 주요했던 이슈

### Anthropic - 에이전트

```
당신은 스타트업에 입사한 신입 (Claude)
- CLAUDE.md = 사원증에 적힌 직급/권한
- Skills = 온보딩 때 받은 SOP 매뉴얼들 (필요할 때 꺼내봄)
- Subagents = 협업 요청하는 다른 팀 (슬랙으로 던지고 결과만 받음)
- MCP = 회사가 쓰는 외부 SaaS들 (Notion, Slack, Jira 등 다른 서비스 연동)
- Context, Context Window = 내 모니터 화면 크기 (동시에 띄울 수 있는 창 개수 제한)
```

Codex나 Replicate MCP 보여주기, 


OpenAI -

Google - 주요했던 것

기타에서 모바일 디바이스나 피지컬 ai 정도로 불릿 간략하게 하고 넘어가기

## 4. 대담

## 5. 질의응답


## 마무리 
```
andrej karpathy
넌 어떻게 생각해? 라고 묻지 마세요.
사고 실험 도구, thinking game

각각의 AI들 나는 실제로 어떻게 활용하고 있는지 소개하는 거 

SOTA 관련 - 한번의 경험에 머물러 있지 않는 마인드셋
```

